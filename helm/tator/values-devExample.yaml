# This can be a domain that points to a LAN IP address if you
# are accessing the site from another machine's browser or you
# are installing Tator in a VM. Using localhost only works in 
# a browser running on the same machine running Tator.
domain: &domain localhost
# These domains will work the same way as the primary domain.
#aliases:
#  - domain: alias.duckdns.org
#    # Key filename that will be used in secret for this domain.
#    tlsKeyFile: alias_key.key
#    # Cert filename that will be used in secret for this domain.
#    tlsCertFile: alias_cert.crt
#    # Key secret name that will be used in secret for this domain.
#    tlsKeySecretName: alias-tls-key
#    # Cert secret name that will be used in secret for this domain.
#    tlsCertSecretName: alias-tls-cert
# Requests for these domains will be redirected to the actual domain.
#redirects:
#  - domain: mysite.duckdns.org
#    # Key filename that will be used in secret for this domain.
#    tlsKeyFile: mysite_key.key
#    # Cert filename that will be used in secret for this domain.
#    tlsCertFile: mysite_cert.crt
#    # Key secret name that will be used in secret for this domain.
#    tlsKeySecretName: mysite-tls-key
#    # Cert secret name that will be used in secret for this domain.
#    tlsCertSecretName: mysite-tls-cert
# Enables debug mode for gunicorn. Do NOT enable this in production.
tatorDebug: true
# Enables javascript minification.
useMinJs: false
cors:
  # Enable this to allow cross origin resource sharing (CORS).
  enabled: true
  # Value of Access-Control-Allow-Origin header
  origin: "http://localhost:8080"
  # Value of Access-Control-Allow-Methods header
  methods: '*'
# Enable this to turn on "down for maintenance" page.
maintenance: false
# Secret key for django. Feel free to change this.
djangoSecretKey: "9q@$1)+x+zh-3csau(zqhheos2e+ncygac#ol2)1@x2w#kkaer"
postgresHost: "postgis-svc"
# Postgres username. Some make commands expect username django, but otherwise
# it can be changed.
postgresUsername: "django"
# Postgres password. Change this for production.
postgresPassword: "django123"
redisHost: "tator-redis-master"
elasticsearchHost: "elasticsearch-master"
# liveBucket may be left unconfigured if using local minio
liveBucket:
  config: "json in folded block (>- ...)"
  storeType: "<one of AWS, MINIO, GCP, or OCI>"
  name: "<your bucket name>"
  # proxy: "<proxy domain, if required>"
# If you are using the docker registry container for your registry, you can
# leave these, otherwise change user/pass to the credentials for your registry.
dockerUsername: "test"
dockerPassword: "test"
dockerRegistry: "localhost:5000"
systemImageRepo: "localhost:5000"
#podGCStrategy: "OnWorkflowCompletion"
#slackToken: "<Your slack API token>" # Optional, for slack notifications
#slackChannel: "<Your slack channel ID>" # Optional, for slack notifications
# Enable this to require HTTPS. Be sure to set true for production deployments!
requireHttps: false
certCron:
  # Enable this to enable a cron job to automatically update certificates
  # periodically from LetsEncrypt. If this is not provided, the Secret objects
  # tls-cert and tls-key must be created manually.
  enabled: false
maintenanceCron:
  # Enable this to allow maintenance cron jobs to run, such as garbage collection
  # of deleted database objects and database backups.
  enabled: true
migrations:
  # Enable this if database migrations are allowed.
  enabled: true
# List of storage classes for use by workflows. One of these will be randomly
# passed as a workflow parameter to algorithm workflows, and randomly selected
# for transcode workflows.
workflowStorageClasses:
  - nfs-client
pv:
  nfsServer: "127.0.0.1"
  nfsMountOptions:
    - nfsvers=4.1
  path: "/media/kubernetes_share"
# Can optionally supply seperate pv for static files:
# staticPv:
#   enabled: true
#   nfsServer: "192.168.1.220"
#   nfsMountOptions:
#     - nfsvers=4
#     - nolock
#   path: "/media/kubernetes_alt"
#
pvc:
  size: 10Ti
hpa:
  nginxMinReplicas: 1
  nginxMaxReplicas: 10
  nginxCpuPercent: 50
  gunicornMinReplicas: 1
  gunicornMaxReplicas: 10
  gunicornCpuPercent: 50
metallb:
  # Enable this to provide a load balancer implementation on bare metal.
  enabled: true
  existingConfigMap: metallb-config
  # Change these to your LAN IP if you are accessing Tator via a browser on
  # another machine or you are running Tator in a VM.
  ipRangeStart: 127.0.0.1
  ipRangeStop: 127.0.0.1
  loadBalancerIp: 127.0.0.1
postgis:
  # Enable this if you want to use the postgis docker image.
  enabled: true
  persistence:
    size: 10Gi
  hostPath: /media/kubernetes_share/postgis
redis:
  # Enable this to install the redis helm chart.
  enabled: true
  architecture: standalone
  master:
    persistence:
      enabled: false
  nodeSelector:
    dbServer: "yes"
  usePassword: false
  auth:
    enabled: false
metrics-server:
  enabled: true
  args:
    - --v=2
    - --kubelet-insecure-tls=true
    - --kubelet-preferred-address-types=InternalIP
elasticsearch:
  # Enable this to install the elasticsearch helm chart.
  enabled: true
  persistence:
    enabled: true
  replicas: 1
  clusterHealthCheckParams: wait_for_status=yellow&timeout=1s
  volumeClaimTemplate:
    accessModes: [ "ReadWriteOnce" ]
    resources:
      requests:
        storage: 30Gi
  nodeSelector: 
    dbServer: "yes"
  hostPath: /media/kubernetes_share/elasticsearch
filebeat:
  enabled: true
  image: docker.elastic.co/beats/filebeat-oss
  imageTag: 7.10.2
  filebeatConfig:
    filebeat.yml: |
      filebeat.inputs:
      - type: container
        paths:
        - /var/log/containers/*.log
        processors:
        - add_kubernetes_metadata:
            host: '${NODE_NAME}'
            matchers:
            - logs_path:
                logs_path: "/var/log/containers/"
      output.elasticsearch:
        hosts: ['${ELASTICSEARCH_HOST:elasticsearch-master}:${ELASTICSEARCH_PORT:9200}']
      setup.ilm.enabled: false
kibana:
  enabled: true
  image: docker.elastic.co/kibana/kibana-oss
  imageTag: 7.10.2
  kibanaConfig:
    kibana.yml: |
      server:
        basePath: /logs
minio:
  enabled: true
  accessKey: "AKIAIOSFODNN7EXAMPLE"
  secretKey: "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
  config: >-
    {
      "aws_access_key_id": "AKIAIOSFODNN7EXAMPLE",
      "aws_secret_access_key": "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY",
      "endpoint_url": "http://tator-minio:9000",
      "region_name": "us-east-2"
    }
  storeType: "MINIO"
  name: tator
  persistence:
    size: "1Ti"
    existingClaim: "main-pv-claim"
    subPath: "objects"
  defaultBucket:
    enabled: true
    name: tator
kube-prometheus-stack:
  enabled: true
  prometheus:
    server:
      extraArgs:
        web.external-url: /prometheus/
        web.route-prefix: "/"
    prometheusSpec:
      storageSpec:
        volumeClaimTemplate:
          spec:
            storageClassName: microk8s-hostpath
            resources:
              requests:
                storage: 1Gi
      additionalScrapeConfigs:
        - job_name: node_exporter
          scrape_interval: 10s
          metrics_path: "/metrics"
          static_configs:
            - targets: ["tator-prometheus-node-exporter:9100"]
        - job_name: statsd_exporter
          scrape_interval: 10s
          metrics_path: "/metrics"
          static_configs:
            - targets: ["tator-prometheus-statsd-exporter:9102"]
        - job_name: nginx_status
          scrape_interval: 10s
          metrics_path: "/metrics"
          static_configs:
            - targets: ["nginx-svc:9113"]
  grafana:
    grafana.ini:
      server:
        domain: *domain
        root_url: "%(protocol)s://%(domain)s/grafana/"
        serve_from_sub_path: true
      auth.anonymous:
        enabled: true
        org_role: Admin
prometheus-adapter:
  enabled: true
  prometheus:
    url: http://prometheus-operated
    port: 9090
  rules:
    default: false
    resource:
      cpu:
        containerQuery: sum(rate(container_cpu_usage_seconds_total{<<.LabelMatchers>>, container!=""}[3m])) by (<<.GroupBy>>)
        nodeQuery: sum(rate(container_cpu_usage_seconds_total{<<.LabelMatchers>>, id='/'}[3m])) by (<<.GroupBy>>)
        resources:
          overrides:
            node:
              resource: node
            namespace:
              resource: namespace
            pod:
              resource: pod
        containerLabel: container
      memory:
        containerQuery: sum(container_memory_working_set_bytes{<<.LabelMatchers>>, container!=""}) by (<<.GroupBy>>)
        nodeQuery: sum(container_memory_working_set_bytes{<<.LabelMatchers>>,id='/'}) by (<<.GroupBy>>)
        resources:
          overrides:
            node:
              resource: node
            namespace:
              resource: namespace
            pod:
              resource: pod
        containerLabel: container
      window: 3m
# Limits on resources for transcode workflows.
transcoderMaxRamDiskSize: "2Gi"
transcoderCpuLimit: "1000m"
transcoderMemoryLimit: "4Gi"
remoteTranscodes:
  # Typically for dev processing is done on the same machine.
  enabled: false
  # Host/port are obtained via the following (run on the transcode cluster):
  #   echo $(kubectl config view --minify | grep server | cut -f 2- -d ":" | tr -d " ")
  host: "your.transcode.domain.org"
  port: "6443"
  # Token can be obtained via the following (run on the transcode cluster):
  #   SECRET_NAME=$(kubectl get secrets | grep ^default | cut -f1 -d ' ')
  #   TOKEN=$(kubectl describe secret $SECRET_NAME | grep -E '^token' | cut -f2 -d':' | tr -d " ")
  #   echo $TOKEN
  token: "Bearer <Your token here>"
  # Certificate can be obtained via the following (run on the transcode cluster):
  #   SECRET_NAME=$(kubectl get secrets | grep ^default | cut -f1 -d ' ')
  #   CERT=$(kubectl get secret $SECRET_NAME -o yaml | grep -E '^  ca.crt' | cut -f2 -d':' | tr -d " ")
  #   echo $CERT | base64 --decode
  cert: |
    -----BEGIN CERTIFICATE-----
    <Insert certificate here>
    -----END CERTIFICATE-----
cognito:
  enabled: false
  config: |
    aws-region: us-east-2
    pool-id: <POOL ID HERE>
    client-id: <ID HERE>
okta:
  enabled: false
  oauth2_key: "fill me in"
  oauth2_secret: "fill me in"
  oauth2_token_uri: "fill me in"
  oauth2_issuer: "fill me in"
  oauth2_auth_uri: "fill me in"
saml:
  enabled: false
  metadata_url: "fill me in"
  sso_url: "fill me in"
email:
  enabled: false
  sender: "<fill in>"
  aws_region: "<fill in>"
  aws_access_key_id: "<fill in>"
  aws_secret_access_key: "<fill in>"
anonymousRegistration:
  # Enable this to allow users to register without an organizational invitation.
  enabled: false
  # Enable this to require email confirmation after anonymous registration.
  emailConfirmation: false
organizations:
  # Autocreate on new user registration.
  autocreate: true
  # Disable to allow POST for staff only.
  allowPost: true

